{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ew23abo/MSc-Final-Year-Project/blob/main/Custom_CNN_MM_SEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgzZo__nV4gN"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73j9y5a1WAQW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Enable memory growth for GPUs (avoid crashes)\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "# Load PatchCamelyon dataset efficiently\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    'patch_camelyon',\n",
        "    split=['train[:80%]', 'train[80%:]', 'validation'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Verify loaded dataset\n",
        "print(f\"Dataset Info:\\n{ds_info}\")\n",
        "\n",
        "# Example: view a sample image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_sample(image, label):\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(f\"Label: {label.numpy()}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "for image, label in ds_train.take(1):\n",
        "    show_sample(image, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQlsdkzuWASr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the dataset\n",
        "ds_train, ds_info = tfds.load('patch_camelyon', split='train', with_info=True, as_supervised=True)\n",
        "\n",
        "# Display 5 sample images with labels\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i, (image, label) in enumerate(ds_train.take(5)):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(f'Label: {label.numpy()}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7LX0YW_WAWR"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Enable GPU memory growth to avoid runtime crashes\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "# Load PCam dataset with 80% train and 20% test split\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'patch_camelyon',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Verify dataset info\n",
        "print(ds_info)\n",
        "\n",
        "# Define preprocessing and augmentation functions\n",
        "def preprocess(image, label):\n",
        "    # Normalise images to [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    # Resize images to ensure consistent input size (if required by your models)\n",
        "    image = tf.image.resize(image, [96, 96])\n",
        "    return image, label\n",
        "\n",
        "# Augmentation function according to PDM plan (rotation, flip, contrast)\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)  # Ensure pixel values are within [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing, augmentation, batching, caching, and prefetching\n",
        "batch_size = 64\n",
        "\n",
        "# Training dataset pipeline\n",
        "ds_train = (\n",
        "    ds_train\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(1000)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Test dataset pipeline (no augmentation, just preprocessing)\n",
        "ds_test = (\n",
        "    ds_test\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Check a batch of training images\n",
        "for images, labels in ds_train.take(1):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "        plt.title(f'Label: {labels[i].numpy()}')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgMldHfnWAYq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Concatenate, Multiply, Activation, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def simple_attention_block(x):\n",
        "    channels = x.shape[-1]\n",
        "    attention = GlobalAveragePooling2D()(x)\n",
        "    attention = Dense(channels//4, activation='relu')(attention)\n",
        "    attention = Dense(channels, activation='sigmoid')(attention)\n",
        "    attention = Reshape((1, 1, channels))(attention)\n",
        "    return Multiply()([x, attention])\n",
        "\n",
        "input_layer = Input(shape=(96, 96, 3))\n",
        "\n",
        "# Multi-scale convolutional branches\n",
        "branch1 = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
        "branch2 = Conv2D(32, (5,5), activation='relu', padding='same')(input_layer)\n",
        "branch3 = Conv2D(32, (7,7), activation='relu', padding='same')(input_layer)\n",
        "\n",
        "# Combine branches\n",
        "combined = Concatenate()([branch1, branch2, branch3])\n",
        "\n",
        "# Apply attention\n",
        "attention_output = simple_attention_block(combined)\n",
        "\n",
        "# Pooling and classification\n",
        "x = GlobalAveragePooling2D()(attention_output)\n",
        "output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Define model\n",
        "custom_mmsen_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile model clearly\n",
        "custom_mmsen_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "custom_mmsen_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQy_ig6zWAbO"
      },
      "outputs": [],
      "source": [
        "history_custom_mmsen = custom_mmsen_model.fit(\n",
        "    ds_train,\n",
        "    epochs=20,\n",
        "    validation_data=ds_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g773AMXFWAdV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Reshape, Multiply\n",
        "\n",
        "def simple_attention_block(x):\n",
        "    channels = x.shape[-1]  # explicitly defining 'channels' based on input tensor 'x'\n",
        "    attention = GlobalAveragePooling2D()(x)\n",
        "    attention = Dense(channels // 2, activation='relu')(attention)  # your modified line\n",
        "    attention = Dense(channels, activation='sigmoid')(attention)\n",
        "    attention = Reshape((1, 1, channels))(attention)\n",
        "    return Multiply()([x, attention])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK0yho-UrDvx"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the custom model (additional 10 epochs with lower learning rate)\n",
        "\n",
        "# Adjust the learning rate for stable fine-tuning\n",
        "custom_mmsen_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Fine-tuning training\n",
        "history_finetune_custom_mmsen = custom_mmsen_model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    validation_data=ds_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo3ZHLYTx0Sz"
      },
      "outputs": [],
      "source": [
        "# Required imports for visualisation and evaluation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Function to plot training curves\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['auc'], label='AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "    plt.title('AUC-ROC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L5cEDFwx-KG"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate model performance\n",
        "def evaluate_model(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions = np.round(predictions).astype(int)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predictions.flatten())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    print(\"\\nCustom MM-SEN-Inspired Model Evaluation Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpwNubNBx-CR"
      },
      "outputs": [],
      "source": [
        "# Function to visualise model predictions on test images\n",
        "def visualize_predictions(model, dataset, num_images=20):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images_shown = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions_rounded = np.round(predictions).astype(int).flatten()\n",
        "\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 5, images_shown + 1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {predictions_rounded[i]}\")\n",
        "            plt.axis('off')\n",
        "            images_shown += 1\n",
        "\n",
        "            if images_shown >= num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return\n",
        "\n",
        "# Execute clearly after training\n",
        "plot_training_curves(history_custom_mmsen)\n",
        "evaluate_model(custom_mmsen_model, ds_test)\n",
        "visualize_predictions(custom_mmsen_model, ds_test, num_images=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUYnBwrQvuRe"
      },
      "outputs": [],
      "source": [
        "# Required imports for visualisation and evaluation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Function to plot training curves\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['auc'], label='AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "    plt.title('AUC-ROC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions = np.round(predictions).astype(int)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predictions.flatten())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    print(\"\\nCustom MM-SEN-Inspired Model Evaluation Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "# Function to visualise model predictions on test images\n",
        "def visualize_predictions(model, dataset, num_images=20):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images_shown = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions_rounded = np.round(predictions).astype(int).flatten()\n",
        "\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 5, images_shown + 1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {predictions_rounded[i]}\")\n",
        "            plt.axis('off')\n",
        "            images_shown += 1\n",
        "\n",
        "            if images_shown >= num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return\n",
        "\n",
        "# Further fine-tuning the custom model (additional 10 epochs with even lower learning rate)\n",
        "custom_mmsen_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Execute further fine-tuning\n",
        "history_finetune_extended = custom_mmsen_model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    validation_data=ds_test\n",
        ")\n",
        "\n",
        "# Evaluate and visualize clearly after additional fine-tuning\n",
        "plot_training_curves(history_finetune_extended)\n",
        "evaluate_model(custom_mmsen_model, ds_test)\n",
        "visualize_predictions(custom_mmsen_model, ds_test, num_images=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EvXw1n24QRw"
      },
      "outputs": [],
      "source": [
        "# Required imports for visualisation and evaluation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Function to plot training curves\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['auc'], label='AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "    plt.title('AUC-ROC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to visualise model predictions on test images\n",
        "def visualize_predictions(model, dataset, num_images=20):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images_shown = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions_rounded = np.round(predictions).astype(int).flatten()\n",
        "\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 5, images_shown + 1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {predictions_rounded[i]}\")\n",
        "            plt.axis('off')\n",
        "            images_shown += 1\n",
        "\n",
        "            if images_shown >= num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K3H8XTW36pe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions = np.round(predictions).astype(int)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predictions.flatten())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    print(\"\\nCustom MM-SEN-Inspired Model Evaluation Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPvTDGK67fuF"
      },
      "source": [
        "# Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EVN2nbY7G1G"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install --upgrade tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk-vLaO47G3K"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaXHJdXg7154"
      },
      "source": [
        "# Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvRybd3RFEUi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Enable memory growth for GPUs (avoid crashes)\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "# Load PatchCamelyon dataset efficiently\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    'patch_camelyon',\n",
        "    split=['train[:80%]', 'train[80%:]', 'validation'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Verify loaded dataset\n",
        "print(f\"Dataset Info:\\n{ds_info}\")\n",
        "\n",
        "# Example: view a sample image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_sample(image, label):\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(f\"Label: {label.numpy()}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "for image, label in ds_train.take(1):\n",
        "    show_sample(image, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KI4bCoNGku0"
      },
      "outputs": [],
      "source": [
        "# Define preprocessing and augmentation functions\n",
        "def preprocess(image, label):\n",
        "    # Normalise images to [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    # Resize images to ensure consistent input size (if required by your models)\n",
        "    image = tf.image.resize(image, [96, 96])\n",
        "    return image, label\n",
        "\n",
        "# Augmentation function according to PDM plan (rotation, flip, contrast)\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)  # Ensure pixel values are within [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing, augmentation, batching, caching, and prefetching\n",
        "batch_size = 64\n",
        "\n",
        "# Training dataset pipeline\n",
        "ds_train = (\n",
        "    ds_train\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(1000)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Test dataset pipeline (no augmentation, just preprocessing)\n",
        "ds_test = (\n",
        "    ds_test\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Check a batch of training images\n",
        "for images, labels in ds_train.take(1):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "        plt.title(f'Label: {labels[i].numpy()}')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfR-fE0c7-FT"
      },
      "source": [
        "# Define the Custom MM-SEN-Inspired Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhN6ep0E7G8Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Concatenate, Multiply, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def simple_attention_block(x):\n",
        "    channels = x.shape[-1]\n",
        "    attention = GlobalAveragePooling2D()(x)\n",
        "    attention = Dense(channels // 2, activation='relu')(attention)\n",
        "    attention = Dense(channels, activation='sigmoid')(attention)\n",
        "    attention = Reshape((1, 1, channels))(attention)\n",
        "    return Multiply()([x, attention])\n",
        "\n",
        "input_layer = Input(shape=(96, 96, 3))\n",
        "\n",
        "branch1 = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
        "branch2 = Conv2D(32, (5,5), activation='relu', padding='same')(input_layer)\n",
        "branch3 = Conv2D(32, (7,7), activation='relu', padding='same')(input_layer)\n",
        "\n",
        "combined = Concatenate()([branch1, branch2, branch3])\n",
        "attention_output = simple_attention_block(combined)\n",
        "x = GlobalAveragePooling2D()(attention_output)\n",
        "output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "custom_mmsen_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "custom_mmsen_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXPN3Sf18CXO"
      },
      "source": [
        "# Compile and Train the Model (40 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u02VKqUv7G_S"
      },
      "outputs": [],
      "source": [
        "custom_mmsen_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Train for 40 epochs\n",
        "history_custom_mmsen = custom_mmsen_model.fit(\n",
        "    ds_train,\n",
        "    epochs=40,\n",
        "    validation_data=ds_test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfgdrV1n8KfU"
      },
      "source": [
        "# Visualisation and Evaluation After Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY_4CIwp7HEM"
      },
      "outputs": [],
      "source": [
        "# Plotting function\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    epochs = np.arange(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(epochs, history.history['accuracy'], label='Accuracy')\n",
        "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(epochs)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(epochs, history.history['loss'], label='Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xticks(epochs)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(epochs, history.history['auc'], label='AUC')\n",
        "    plt.plot(epochs, history.history['val_auc'], label='Validation AUC')\n",
        "    plt.title('AUC-ROC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.xticks(epochs)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        preds = model.predict(images)\n",
        "        preds = np.round(preds).astype(int).flatten()\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_pred))\n",
        "\n",
        "# Run evaluation and visualisation\n",
        "plot_training_curves(history_custom_mmsen)\n",
        "evaluate_model(custom_mmsen_model, ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olb9t4MoJFFN"
      },
      "outputs": [],
      "source": [
        "# Function to visualise predictions on 20 test images clearly\n",
        "def visualize_predictions(model, dataset, num_images=20):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images_shown = 0\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        preds_rounded = np.round(predictions).astype(int).flatten()\n",
        "\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 5, images_shown + 1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {preds_rounded[i]}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            images_shown += 1\n",
        "            if images_shown >= num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return\n",
        "\n",
        "# Execute clearly after your training and evaluation\n",
        "visualize_predictions(custom_mmsen_model, ds_test, num_images=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAmm7Uvt8RDk"
      },
      "source": [
        " # Fine-tuning (Further 10 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leHFxMee7HGF"
      },
      "outputs": [],
      "source": [
        "# Lower learning rate and fine-tune\n",
        "custom_mmsen_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Further training\n",
        "history_finetune_custom_mmsen = custom_mmsen_model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    validation_data=ds_test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRMaYUdF8V98"
      },
      "source": [
        "# Final Evaluation and Visualisation After Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tcep_l_J8cl"
      },
      "outputs": [],
      "source": [
        "# Evaluate and visualise after fine-tuning (additional 10 epochs)\n",
        "plot_training_curves(history_finetune_custom_mmsen)\n",
        "evaluate_model(custom_mmsen_model, ds_test)\n",
        "\n",
        "# Clearly visualise predictions on 20 test images after fine-tuning\n",
        "def visualize_predictions(model, dataset, num_images=20):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images_shown = 0\n",
        "    for images, labels in dataset:\n",
        "        predictions = model.predict(images)\n",
        "        preds_rounded = np.round(predictions).astype(int).flatten()\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 5, images_shown + 1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {preds_rounded[i]}\")\n",
        "            plt.axis('off')\n",
        "            images_shown += 1\n",
        "            if images_shown >= num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return\n",
        "\n",
        "# Execute visualisation after fine-tuning\n",
        "visualize_predictions(custom_mmsen_model, ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91d6ZauIA8v6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        preds = model.predict(images)\n",
        "        preds = np.round(preds).astype(int).flatten()\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Metastatic', 'Metastatic'])\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Run after training\n",
        "plot_confusion_matrix(custom_mmsen_model, ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "176qFdmyA8zc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def plot_roc_curve(model, dataset):\n",
        "    y_true, y_scores = [], []\n",
        "    for images, labels in dataset:\n",
        "        preds = model.predict(images).flatten()\n",
        "        y_scores.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "    auc_score = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Run after training\n",
        "plot_roc_curve(custom_mmsen_model, ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAW-LKR2A86P"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "def plot_precision_recall_curve(model, dataset):\n",
        "    y_true, y_scores = [], []\n",
        "    for images, labels in dataset:\n",
        "        preds = model.predict(images).flatten()\n",
        "        y_scores.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "    ap_score = average_precision_score(y_true, y_scores)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=f'PR Curve (AP = {ap_score:.4f})')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Run after training\n",
        "plot_precision_recall_curve(custom_mmsen_model, ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lepHcG8i6fN"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TWmZNkQjA__"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def generate_grad_cam(model, image, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(np.array([image]))\n",
        "        loss = predictions[:, 0]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(conv_outputs, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(conv_outputs)\n",
        "\n",
        "    heatmap = cv2.resize(heatmap, (96, 96))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = heatmap * 0.4 + (image * 255)\n",
        "    superimposed_img = np.clip(superimposed_img / superimposed_img.max(), 0, 1)\n",
        "\n",
        "    return superimposed_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnSCFf-sj_vt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example usage (clearly run with one test image)\n",
        "for images, labels in ds_test.take(1):\n",
        "    image = images[0].numpy()\n",
        "    grad_cam_result = generate_grad_cam(custom_mmsen_model, image, last_conv_layer_name='conv2d_2')\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(grad_cam_result)\n",
        "    plt.title('Grad-CAM')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJxYKURljKmO"
      },
      "outputs": [],
      "source": [
        "custom_mmsen_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRxAG1yxlNDS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load small demo subset (20 images) from the test set\n",
        "demo_dataset = ds_test.unbatch().take(20).batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYVwDjzylNF9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for img, label in demo_dataset:\n",
        "    pred = custom_mmsen_model.predict(img)\n",
        "    predictions.append(np.round(pred).astype(int).flatten()[0])\n",
        "    true_labels.append(label.numpy().flatten()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZNNDm6glTd8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i, (img_batch, pred, true_label) in enumerate(zip(demo_dataset, predictions, true_labels)):\n",
        "    image = img_batch[0].numpy().squeeze()\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"True: {true_label} | Pred: {pred}\", fontsize=12, color=\"blue\" if pred==true_label else \"red\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWdmBQaGlaC9"
      },
      "outputs": [],
      "source": [
        "# Interactive prediction function clearly for demo purposes\n",
        "def predict_single_image(model, image):\n",
        "    pred = model.predict(tf.expand_dims(image, axis=0))\n",
        "    pred_label = int(np.round(pred).flatten()[0])\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Model Prediction: {pred_label}\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Clearly pick a random image from your demo set for interactive demonstration\n",
        "for img, label in demo_dataset.take(1):\n",
        "    predict_single_image(custom_mmsen_model, img.numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiC3MPDImdmk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Interactive prediction function showing both true and predicted labels\n",
        "def predict_single_image(model, image, true_label):\n",
        "    pred = model.predict(tf.expand_dims(image, axis=0))\n",
        "    pred_label = int(np.round(pred).flatten()[0])\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"True Label: {true_label} | Model Prediction: {pred_label}\",\n",
        "              fontsize=14,\n",
        "              color=\"blue\" if pred_label == true_label else \"red\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Clearly demonstrate predictions on 4 images interactively\n",
        "for img_batch, label_batch in demo_dataset.take(4):\n",
        "    image = img_batch[0].numpy().squeeze()\n",
        "    true_label = label_batch.numpy()[0]\n",
        "    predict_single_image(custom_mmsen_model, image, true_label)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}