{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPvTDGK67fuF"
   },
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EVN2nbY7G1G",
    "outputId": "bebe13a3-84fc-438f-db81-b59281008e2f"
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install --upgrade tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gk-vLaO47G3K"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaXHJdXg7154"
   },
   "source": [
    "# Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "39c223842c364b37aa4a8fdff2868ee8",
      "f2776572efbb40a2bd2cf44ccca3af10",
      "d573b1f74b1644db9875df3fbb17c7cc",
      "35f436d73e394754995f875584bdd82f",
      "e0810ca2223c46bbb666117d3b3624ef",
      "ef71a3683f7049b69b4f4eaf4bccc199",
      "77b94522929c407aaaa37325118ebf61",
      "dcf2d2f83c9d41179935151f99f3d662",
      "717879ac365d4b6bab1793e45d7adaf6",
      "e5a1bb87351f4577a83841f5f3ea7c8a",
      "f072d79e3deb4e10bb46fb20d32f8fe4",
      "ff05b90452c741b0aa16b0e65e74d122",
      "6cf98d2cb4654efdb391f029f70b4959",
      "275f9a25b5ac420b928aafefc25e8aa6",
      "cb98c6391de644a5a096d0fdc8d1b7dd",
      "6d04c0e8a10d4e649cfecd37c0f3b68f",
      "7882cc42932e4090a3ac66105347cc8a",
      "ed607ff5ecf345f3904d5da1f82104f7",
      "642ee64b529548ab8ff09576d978acc7",
      "36bbd1833fb543eb9729bf2c0b7a6c92",
      "906c432fdaa0408495a2c510aa32ed91",
      "ba76d036b826442cb87bf38654cdba4c",
      "60cdc3dcfdc6491e9977e4e0f69abadf",
      "a2473e5541c0413d89ee6499493d9bb5",
      "ebe866257d834478a17f86f2297ed893",
      "a08f9c71d2da45b2806254b52dc2e060",
      "efce75763b40462da9e19b8dafb55856",
      "bbe80adcb86140188b225d179ecec336",
      "b1ed1c29990b40d398085fed0419f0e9",
      "a13b92e685a646eda67c3fbb3de687da",
      "8b42803649ba425cab6a03ddef544c99",
      "78abd971327941668e2df3096f215ef0",
      "79d8febea2d44eae8834ea345b2e8fb8",
      "6c7bcfa60c8344d3b80fd31bb52bac75",
      "03b2e01e60ab4e2d945cb2530962d9fa",
      "ccdbfe1e55d242928d2c2484a517930d",
      "557fae55263945d99eccde88162a1e36",
      "028042aa22d648c3be48c463f033a150",
      "49a7264655a7459180df9fbe8ed4485b",
      "aa9d6cfb436a4fb29bd492f89d40040f",
      "5e8a04817dbc4da88de2d5c6f302c6a7",
      "cb6224aba1a64110a3f6fdfb17f916d7",
      "ba39178af8204c159d2b49212d4573fd",
      "37a0ef7a5ad047829baf03ea922e97f2",
      "5d9db93f988b446c84b4c23c3c187c4b",
      "1d741a1536d5434bbcc5af23013f71d6",
      "e36be6561ed947b0a59730a6fbee6263",
      "f3ccb75891124a928ee8efafd1815d2d",
      "94e5d7c1e54c4c55ad73f3e39488538b",
      "9567aae53c2a4d8084e710a3a4c8e4c3",
      "8aeca9ed2d69403590507adacf6988d1",
      "680c4c2682124d8cbe373e5512bb83e1",
      "3e363cf39cfa4d57ba2e073054b74f45",
      "04906b6af0134a298ed192593b246e48",
      "6bac8d4818804d71bb1ceead3c1c73eb",
      "59fafcc4552f46ca89073f9a3fcfd05f",
      "878331169bce41a09166707415d2c2ec",
      "a78d8accecb647d3b30bdc59d0c1e378",
      "a6930a6b871c4c14b74f2918e76f55e0",
      "5fc4f55ab5034530b10d44a48a9786fd",
      "781dccdebd73474e8ffa0e23e4d7658a",
      "a5d85794b1c544898eb8c0eaca4ee47d",
      "1a1493431e28431290201659bece8dfb",
      "b0ca8e04607243ba82a1dc2c18796a6f",
      "c4259cbe0750451187e98e48b132bdad",
      "f3f1b099e285470aae12d9fd4f721cb8",
      "2535f32afeac41948ba6acf03c3e0ad0",
      "90b1df8b97f843ffaaafcc955d320442",
      "3af10ed9d1c2493f8568e217323d7eea",
      "81072fc885d145d9abcf3b47a3a6b3f6",
      "a7ee008a101a4da49e3f32e2ea759579",
      "b7c3b203575043bfb1aaac71fb78d961",
      "c4234756144b4b2c823d6616f6d08192",
      "b3d630e261bb494eba9fcb367b7ccde0",
      "3841ac41941448ae9d8419e07c23f815",
      "89461045148f46cb82119e91fa7bbec6",
      "4cee398e5ed64603b2abd5d5e523fd72",
      "2a8d25a360c14494b08daa1afbecdfa7",
      "7b640227324f41e6bab50f83a8050bce",
      "7eea3dfac44f4f0d8cb50a20e9ac333b",
      "b85712b5b82142dba96b1b40056fbbe7",
      "614348adfc2344e5afd0ac893f789fd0",
      "7202e19ae94049fda3af3b5f7cf0501d",
      "1a7adc9aaf364990aa754c214524c1c9",
      "d3823db4cfbb448f99a29ef1f2a2eca4",
      "7f0d4600c95d4eeaadec8c18f63a5b75",
      "dc7526d80af747f38f52e4a6124db994",
      "e63c7cf397014fc788117c37a49d01c6",
      "ce39eddec3f74261bd6baca6d6ebcd31",
      "4bbd7fd7cd3e403288646e7ebaf40366",
      "5d1477e69b9a46469d9b92329a5e9dae",
      "f10fcaba025e481f92edb50fb5f824c2",
      "8ef3c88459b84906bcca633a897eafc6",
      "ef3474634c904c5f9cff7a191b5245ae",
      "703e687bdb6f479cb85df641e33a0490",
      "63065cd6404e4a46803c3b12059bc582",
      "8a09a19bc43c4ba6a049d331faae07f5",
      "41632b55482d4afe98a753d910a3ab78",
      "822f32fb95884a1086c9820bad4e7d0f",
      "89f8c58272404627b23ad96818302264",
      "b7311b14674740838d414488f0a3fff3",
      "250ff3f9fa7b48ecb8757248b8a5cbf8",
      "974e230d11424381ba00cef5d2cac697",
      "083a65bc74dd4fa48ce9412e7242027a",
      "264a5cb2e19f4ec6bb943496b07fbed4",
      "3212c7576b624417b69246a387305f66",
      "3686ac132eb54a26a5ab47f84ee80db7",
      "b51577b150ab465aa1e039d18cdcf92d",
      "1b92ee84b4c240cdae3487eccdf9c656",
      "91217adae12a48f884102354872c8b9b"
     ]
    },
    "id": "wvRybd3RFEUi",
    "outputId": "8cbf8fc7-5487-4c1d-afe6-cab72583cc8b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Enable memory growth for GPUs (avoid crashes)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# Load PatchCamelyon dataset efficiently\n",
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "    'patch_camelyon',\n",
    "    split=['train[:80%]', 'train[80%:]', 'validation'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "# Verify loaded dataset\n",
    "print(f\"Dataset Info:\\n{ds_info}\")\n",
    "\n",
    "# Example: view a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_sample(image, label):\n",
    "    plt.imshow(image.numpy())\n",
    "    plt.title(f\"Label: {label.numpy()}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "for image, label in ds_train.take(1):\n",
    "    show_sample(image, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "7KI4bCoNGku0",
    "outputId": "06a6e301-5b8c-44b2-e836-b525da569daf"
   },
   "outputs": [],
   "source": [
    "# Define preprocessing and augmentation functions\n",
    "def preprocess(image, label):\n",
    "    # Normalise images to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Resize images to ensure consistent input size (if required by your models)\n",
    "    image = tf.image.resize(image, [96, 96])\n",
    "    return image, label\n",
    "\n",
    "# Augmentation function according to PDM plan (rotation, flip, contrast)\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)  # Ensure pixel values are within [0,1]\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing, augmentation, batching, caching, and prefetching\n",
    "batch_size = 64\n",
    "\n",
    "# Training dataset pipeline\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(1000)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Test dataset pipeline (no augmentation, just preprocessing)\n",
    "ds_test = (\n",
    "    ds_test\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .cache()\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Check a batch of training images\n",
    "for images, labels in ds_train.take(1):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        plt.title(f'Label: {labels[i].numpy()}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfR-fE0c7-FT"
   },
   "source": [
    "# Define the Custom MM-SEN-Inspired Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "hhN6ep0E7G8Y",
    "outputId": "d82eea43-a6e5-4400-dbf1-3c949a15e999"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Concatenate, Multiply, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def simple_attention_block(x):\n",
    "    channels = x.shape[-1]\n",
    "    attention = GlobalAveragePooling2D()(x)\n",
    "    attention = Dense(channels // 2, activation='relu')(attention)\n",
    "    attention = Dense(channels, activation='sigmoid')(attention)\n",
    "    attention = Reshape((1, 1, channels))(attention)\n",
    "    return Multiply()([x, attention])\n",
    "\n",
    "input_layer = Input(shape=(96, 96, 3))\n",
    "\n",
    "branch1 = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
    "branch2 = Conv2D(32, (5,5), activation='relu', padding='same')(input_layer)\n",
    "branch3 = Conv2D(32, (7,7), activation='relu', padding='same')(input_layer)\n",
    "\n",
    "combined = Concatenate()([branch1, branch2, branch3])\n",
    "attention_output = simple_attention_block(combined)\n",
    "x = GlobalAveragePooling2D()(attention_output)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "custom_mmsen_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "custom_mmsen_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXPN3Sf18CXO"
   },
   "source": [
    "# Compile and Train the Model (40 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u02VKqUv7G_S",
    "outputId": "cf0df154-2643-4e98-e8a6-cef3bcd89bfa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Compile the custom MM-SEN model\n",
    "custom_mmsen_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Add EarlyStopping to stop training if no improvement in validation loss for 10 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',          # Monitors validation loss\n",
    "    patience=10,                  # Stops if no improvement for 10 epochs\n",
    "    restore_best_weights=True,   # Restores model weights from the best epoch\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add ModelCheckpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/content/custom_mmsen_best_model.h5',   # Path to save the model\n",
    "    monitor='val_loss',                              # Monitors validation loss\n",
    "    save_best_only=True,                              # Saves only the best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping and model checkpoint\n",
    "history_custom_mmsen = custom_mmsen_model.fit(\n",
    "    ds_train,\n",
    "    epochs=40,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[early_stopping, checkpoint]   # Adding both callbacks\n",
    ")\n",
    "\n",
    "# Save the final model after training\n",
    "custom_mmsen_model.save('/content/custom_mmsen_final_model.h5')\n",
    "print(\"Model saved after training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RhVJ1VkduwU",
    "outputId": "dd7021f5-fdad-41e6-d106-54558f5816c2"
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('/content/custom_mmsen_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfgdrV1n8KfU"
   },
   "source": [
    "# Visualisation and Evaluation After Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GY_4CIwp7HEM",
    "outputId": "10cfd8cb-5999-42be-abe4-171cbd606c3c"
   },
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    epochs = np.arange(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, history.history['loss'], label='Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, history.history['auc'], label='AUC')\n",
    "    plt.plot(epochs, history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('AUC-ROC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        preds = np.round(preds).astype(int).flatten()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "# Run evaluation and visualisation\n",
    "plot_training_curves(history_custom_mmsen)\n",
    "evaluate_model(custom_mmsen_model, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-GMnhpaUpcqB",
    "outputId": "8eb2cffd-60f9-43ab-865a-4313a41358e3"
   },
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    epochs = np.arange(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=5))  # Setting step to 5 for clear spacing\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, history.history['loss'], label='Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=5))  # Setting step to 5 for clear spacing\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, history.history['auc'], label='AUC')\n",
    "    plt.plot(epochs, history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('AUC-ROC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=5))  # Setting step to 5 for clear spacing\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        preds = np.round(preds).astype(int).flatten()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "# Run evaluation and visualisation\n",
    "plot_training_curves(history_custom_mmsen)\n",
    "evaluate_model(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "id": "olb9t4MoJFFN",
    "outputId": "c3c26793-9896-4693-cbd1-4db422a121c7"
   },
   "outputs": [],
   "source": [
    "# Function to visualise predictions on 20 test images clearly\n",
    "def visualize_predictions(model, dataset, num_images=20):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    images_shown = 0\n",
    "    for images, labels in dataset:\n",
    "        predictions = model.predict(images)\n",
    "        preds_rounded = np.round(predictions).astype(int).flatten()\n",
    "\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 5, images_shown + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {preds_rounded[i]}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                return\n",
    "\n",
    "# Execute clearly after your training and evaluation\n",
    "visualize_predictions(custom_mmsen_model, ds_test, num_images=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAmm7Uvt8RDk"
   },
   "source": [
    " # Fine-tuning (Further 10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leHFxMee7HGF",
    "outputId": "bdf42b0e-0fa2-493a-ed96-f2f777bf9d3a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "custom_mmsen_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting during fine-tuning\n",
    "early_stopping_finetune = EarlyStopping(\n",
    "    monitor='val_loss',          # Monitor validation loss\n",
    "    patience=3,                  # Stops if no improvement for 3 epochs\n",
    "    restore_best_weights=True,   # Restores best model weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model checkpoint to save the best fine-tuned model\n",
    "checkpoint_finetune = ModelCheckpoint(\n",
    "    filepath='/content/custom_mmsen_best_finetune_model.h5',  # Save path\n",
    "    monitor='val_loss',                                      # Monitor validation loss\n",
    "    save_best_only=True,                                      # Save only the best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Further fine-tuning for 10 epochs\n",
    "history_finetune_custom_mmsen = custom_mmsen_model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[early_stopping_finetune, checkpoint_finetune]  # Adding callbacks\n",
    ")\n",
    "\n",
    "# Save the final fine-tuned model after training\n",
    "custom_mmsen_model.save('/content/custom_mmsen_finetuned_final.h5')\n",
    "print(\"Fine-tuned model saved after further training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRMaYUdF8V98"
   },
   "source": [
    "# Final Evaluation and Visualisation After Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6tcep_l_J8cl",
    "outputId": "75d4ff2e-c43d-4663-8740-00c9a2e0a4cf"
   },
   "outputs": [],
   "source": [
    "# Evaluate and visualise after fine-tuning (additional 10 epochs)\n",
    "plot_training_curves(history_finetune_custom_mmsen)\n",
    "evaluate_model(custom_mmsen_model, ds_test)\n",
    "\n",
    "# Clearly visualise predictions on 20 test images after fine-tuning\n",
    "def visualize_predictions(model, dataset, num_images=20):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    images_shown = 0\n",
    "    for images, labels in dataset:\n",
    "        predictions = model.predict(images)\n",
    "        preds_rounded = np.round(predictions).astype(int).flatten()\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 5, images_shown + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            plt.title(f\"True: {labels.numpy()[i]} | Pred: {preds_rounded[i]}\")\n",
    "            plt.axis('off')\n",
    "            images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                return\n",
    "\n",
    "# Execute visualisation after fine-tuning\n",
    "visualize_predictions(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "40D6yLO2p6Bt",
    "outputId": "3ef6c536-adc6-4548-c752-1fd32721a3e1"
   },
   "outputs": [],
   "source": [
    "# Plotting function with improved y-axis scaling\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    epochs = np.arange(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.75, 0.90)  # Set y-axis range to better reflect the accuracy spread\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=1))\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, history.history['loss'], label='Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0.30, 0.45)  # Set y-axis range to better capture the loss variations\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=1))\n",
    "    plt.legend()\n",
    "\n",
    "    # AUC-ROC Plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, history.history['auc'], label='AUC')\n",
    "    plt.plot(epochs, history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('AUC-ROC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.ylim(0.10, 0.99)  # Adjust y-axis range to focus on AUC differences\n",
    "    plt.xticks(np.arange(1, len(epochs) + 1, step=1))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        preds = np.round(preds).astype(int).flatten()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "# Run evaluation and visualisation\n",
    "plot_training_curves(history_finetune_custom_mmsen)\n",
    "evaluate_model(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "91d6ZauIA8v6",
    "outputId": "4ec2d8fe-0307-41ba-ac37-506eebab34ef"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(model, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        preds = np.round(preds).astype(int).flatten()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Metastatic', 'Metastatic'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Run after training\n",
    "plot_confusion_matrix(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "176qFdmyA8zc",
    "outputId": "8bf30f26-ec72-47b7-8769-541a5e8b846f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def plot_roc_curve(model, dataset):\n",
    "    y_true, y_scores = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images).flatten()\n",
    "        y_scores.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    auc_score = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Run after training\n",
    "plot_roc_curve(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96yPWXGLe21-",
    "outputId": "a8cc8f56-5833-47ca-ab6b-9ea47ae1b9ca"
   },
   "outputs": [],
   "source": [
    "finetuned_model = tf.keras.models.load_model('/content/custom_mmsen_best_finetune_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XAW-LKR2A86P",
    "outputId": "e9c885e8-4c54-4653-de05-0b64ebaa4bd8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_precision_recall_curve(model, dataset):\n",
    "    y_true, y_scores = [], []\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images).flatten()\n",
    "        y_scores.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    ap_score = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f'PR Curve (AP = {ap_score:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Run after training\n",
    "plot_precision_recall_curve(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lepHcG8i6fN",
    "outputId": "7f3e65f5-e344-4de5-bd91-59f3e60c7b6a"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5TWmZNkQjA__"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def generate_grad_cam(model, image, last_conv_layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([image]))\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(conv_outputs)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (96, 96))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    superimposed_img = heatmap * 0.4 + (image * 255)\n",
    "    superimposed_img = np.clip(superimposed_img / superimposed_img.max(), 0, 1)\n",
    "\n",
    "    return superimposed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "LnSCFf-sj_vt",
    "outputId": "ade4d9c8-01f1-4283-92ae-8dfce7bf1d9b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example usage (clearly run with one test image)\n",
    "for images, labels in ds_test.take(1):\n",
    "    image = images[0].numpy()\n",
    "    grad_cam_result = generate_grad_cam(custom_mmsen_model, image, last_conv_layer_name='conv2d_2')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(grad_cam_result)\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "xJxYKURljKmO",
    "outputId": "b224707e-345a-4561-ddc7-b45739d7b5ec"
   },
   "outputs": [],
   "source": [
    "custom_mmsen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SRxAG1yxlNDS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load small demo subset (20 images) from the test set\n",
    "demo_dataset = ds_test.unbatch().take(20).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYVwDjzylNF9",
    "outputId": "ccb773e0-39e7-4682-8b2a-a73155ff9021"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for img, label in demo_dataset:\n",
    "    pred = custom_mmsen_model.predict(img)\n",
    "    predictions.append(np.round(pred).astype(int).flatten()[0])\n",
    "    true_labels.append(label.numpy().flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "kZNNDm6glTd8",
    "outputId": "327327fc-756f-4bde-ab45-c3d3a4d1aa42"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, (img_batch, pred, true_label) in enumerate(zip(demo_dataset, predictions, true_labels)):\n",
    "    image = img_batch[0].numpy().squeeze()\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_label} | Pred: {pred}\", fontsize=12, color=\"blue\" if pred==true_label else \"red\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "FWdmBQaGlaC9",
    "outputId": "d2d4e806-ada2-495e-9447-1a89eb1d67e5"
   },
   "outputs": [],
   "source": [
    "# Interactive prediction function clearly for demo purposes\n",
    "def predict_single_image(model, image):\n",
    "    pred = model.predict(tf.expand_dims(image, axis=0))\n",
    "    pred_label = int(np.round(pred).flatten()[0])\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Model Prediction: {pred_label}\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Clearly pick a random image from your demo set for interactive demonstration\n",
    "for img, label in demo_dataset.take(1):\n",
    "    predict_single_image(custom_mmsen_model, img.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CiC3MPDImdmk",
    "outputId": "872abebd-c0be-46f9-e418-0fb652350a76"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Interactive prediction function showing both true and predicted labels\n",
    "def predict_single_image(model, image, true_label):\n",
    "    pred = model.predict(tf.expand_dims(image, axis=0))\n",
    "    pred_label = int(np.round(pred).flatten()[0])\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True Label: {true_label} | Model Prediction: {pred_label}\",\n",
    "              fontsize=14,\n",
    "              color=\"blue\" if pred_label == true_label else \"red\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Clearly demonstrate predictions on 4 images interactively\n",
    "for img_batch, label_batch in demo_dataset.take(4):\n",
    "    image = img_batch[0].numpy().squeeze()\n",
    "    true_label = label_batch.numpy()[0]\n",
    "    predict_single_image(custom_mmsen_model, image, true_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_BW0lDUnd79i",
    "outputId": "f7b5c13a-16d1-499f-e191-66856979285a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, classification_report\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred_prob):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker='.', label=f'PR Curve (AUC = {auc_pr:.4f})')\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_prob):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, marker='.', label=f'ROC Curve (AUC = {auc_roc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_accuracy(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    classes = ['Non-Metastatic', 'Metastatic']\n",
    "    accuracies = [accuracy_score(y_true == i, y_pred == i) for i in range(2)]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(classes, accuracies, color=['blue', 'orange'])\n",
    "    plt.title(\"Class-wise Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_prediction_distribution(y_pred_prob):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(y_pred_prob, bins=30, alpha=0.7, label='Predicted Probabilities')\n",
    "    plt.title(\"Prediction Probability Distribution\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_misclassified_samples(model, dataset, num_samples=10):\n",
    "    misclassified = []\n",
    "    for images, labels in dataset:\n",
    "        predictions = model.predict(images)\n",
    "        preds = np.round(predictions).astype(int).flatten()\n",
    "        for img, label, pred in zip(images, labels, preds):\n",
    "            if label.numpy() != pred:\n",
    "                misclassified.append((img, label.numpy(), pred))\n",
    "            if len(misclassified) >= num_samples:\n",
    "                break\n",
    "        if len(misclassified) >= num_samples:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (img, true_label, pred_label) in enumerate(misclassified):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(img.numpy())\n",
    "        plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage after model evaluation\n",
    "y_true, y_pred_prob = [], []\n",
    "for images, labels in ds_test:\n",
    "    preds = custom_mmsen_model.predict(images).flatten()\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred_prob.extend(preds)\n",
    "\n",
    "# Plot visuals\n",
    "plot_precision_recall_curve(y_true, y_pred_prob)\n",
    "plot_roc_curve(y_true, y_pred_prob)\n",
    "plot_class_accuracy(np.array(y_true), np.round(y_pred_prob).astype(int))\n",
    "plot_prediction_distribution(y_pred_prob)\n",
    "plot_misclassified_samples(custom_mmsen_model, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wUZ4txF6gbl",
    "outputId": "b9ba0f46-4724-44d5-ea8b-3736e87ab033"
   },
   "outputs": [],
   "source": [
    "!pip install nbconvert nbformat\n",
    "!jupyter nbconvert --to notebook --ClearOutputPreprocessor.enabled=True --inplace your_notebook.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
